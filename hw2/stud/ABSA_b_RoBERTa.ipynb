{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ABSA_b_RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b871ee83b57453bac912a24359b2f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b85555d7ead41e9bc188495e8b2b1db",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18ea6b7bb694413ba3d11922b9cbdb5d",
              "IPY_MODEL_504da1b4c5ca48d890f2384c3ff3632b"
            ]
          }
        },
        "8b85555d7ead41e9bc188495e8b2b1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "18ea6b7bb694413ba3d11922b9cbdb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26f91f427dab4ab091acf8c7dd970316",
            "_dom_classes": [],
            "description": "Validation sanity check: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6ab4f6e8ef14ce1a9d5b2a7eb8253ab"
          }
        },
        "504da1b4c5ca48d890f2384c3ff3632b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_16affebb6f624f8083500095d72b79b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:12&lt;00:00,  6.20s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ace84513c084a10abef7facbc342ce5"
          }
        },
        "26f91f427dab4ab091acf8c7dd970316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6ab4f6e8ef14ce1a9d5b2a7eb8253ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16affebb6f624f8083500095d72b79b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ace84513c084a10abef7facbc342ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bee863634b464596b52f363f9542d93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16d0c6cc999d4658bf507406538cdb9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d0a9910b4d94f42b46186b769384e20",
              "IPY_MODEL_10f8e1ae03354b3aab3a4209527caa1a"
            ]
          }
        },
        "16d0c6cc999d4658bf507406538cdb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "4d0a9910b4d94f42b46186b769384e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6fc64f90ba9a4cb5a453cabc7dafb624",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 159,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 159,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b6a8157207e4a04b615eeba1792f4dd"
          }
        },
        "10f8e1ae03354b3aab3a4209527caa1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ad0965093904cd1bf891f555dc3d1a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 159/159 [04:15&lt;00:00,  1.61s/it, loss=0.583, v_num=2, valid_loss=0.682, valid_f1=0.677, train_loss=0.412, train_f1=0.483]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9fa191ebb244165b4cc3e8c8bc3fa20"
          }
        },
        "6fc64f90ba9a4cb5a453cabc7dafb624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b6a8157207e4a04b615eeba1792f4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ad0965093904cd1bf891f555dc3d1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9fa191ebb244165b4cc3e8c8bc3fa20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "553feaddeb7e48d9bd7f82658cf07bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57751a227cdd446d900ab79dd73b41f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e00a8c622f2543b9ba46a2d8aec1a9f8",
              "IPY_MODEL_e188d3f334f9466794614c0cdefd3196"
            ]
          }
        },
        "57751a227cdd446d900ab79dd73b41f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e00a8c622f2543b9ba46a2d8aec1a9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9754526d0e204fc7993604f101b341e4",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d0b26ccb81143e98dab7d4ffcc6581b"
          }
        },
        "e188d3f334f9466794614c0cdefd3196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2dbe4bbb81094802915155d1b423f723",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:14&lt;00:00,  7.21s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c753fc3139e246bcbcf947f29e2d1ac7"
          }
        },
        "9754526d0e204fc7993604f101b341e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d0b26ccb81143e98dab7d4ffcc6581b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2dbe4bbb81094802915155d1b423f723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c753fc3139e246bcbcf947f29e2d1ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "820382df274641efb9fd3f109d925f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6dade08bf1674298af9191536a16079e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0fb8751415f94180afdc5369b21fc54d",
              "IPY_MODEL_921afc97ed944cafac25c5a3477ef19e"
            ]
          }
        },
        "6dade08bf1674298af9191536a16079e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "0fb8751415f94180afdc5369b21fc54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9cc2a32c6dc749b1a979a777f51cc2b8",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3934b03772c544059cb4acbfe837e97e"
          }
        },
        "921afc97ed944cafac25c5a3477ef19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17536f77c4d84d31bd63355f0cd46c84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:13&lt;00:00,  7.00s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3db5788dfecc44b9adaeffc0c76797e7"
          }
        },
        "9cc2a32c6dc749b1a979a777f51cc2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3934b03772c544059cb4acbfe837e97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17536f77c4d84d31bd63355f0cd46c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3db5788dfecc44b9adaeffc0c76797e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b8ad08b72874289ad9e1f1e50790306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7aba2a194884b6fbbaf479aea1657c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2fed131fc0a14d95a9bc3d5af8b547b3",
              "IPY_MODEL_291f127e83dc4d5b973b90b8c3fbcbf5"
            ]
          }
        },
        "f7aba2a194884b6fbbaf479aea1657c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "2fed131fc0a14d95a9bc3d5af8b547b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c773b070e04347de9245253cb6f6e36d",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_505c86961eb74475979dcafce8366ad7"
          }
        },
        "291f127e83dc4d5b973b90b8c3fbcbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c8908810b8f4d2e80981a33f9e29b74",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:13&lt;00:00,  6.92s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_714c011cf70242d8b2806324902d1704"
          }
        },
        "c773b070e04347de9245253cb6f6e36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "505c86961eb74475979dcafce8366ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c8908810b8f4d2e80981a33f9e29b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "714c011cf70242d8b2806324902d1704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd4nhu0rW0KI"
      },
      "source": [
        "# NLP - Homework 2 - task b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt4_9lkCXAoQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGuLp1gcXBSM",
        "outputId": "c42be6e5-272c-43ac-d6fa-755c17a50823"
      },
      "source": [
        "# install lightning\n",
        "!pip install pytorch_lightning &> /dev/null\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZgKgr7UXGq5",
        "outputId": "5760272d-3f9c-4e63-8162-b340478a0047"
      },
      "source": [
        "# here go all the imports\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from pprint import pprint\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import *\n",
        "from string import punctuation\n",
        "\n",
        "# huggingface's transformers library\n",
        "import transformers\n",
        "from transformers import RobertaTokenizer\n",
        "\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "torch.__version__, torch.cuda.get_device_name(0), transformers.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.8.1+cu101', 'Tesla T4', '4.6.1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DElQuFVyXKyj"
      },
      "source": [
        "## Allow reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "magZY8MfXNKK"
      },
      "source": [
        "VARIANTS = {'Average Last Four Hidden', 'Sum Last Four Hidden', 'INS', 'ISNS', 'ENS', 'ATPC with sqrt', 'ATPC'}\n",
        "VARIANT_TO_TEST = 'ATPC with sqrt'\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True  # will use only deterministic algorithms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAbmO-JPXTDQ"
      },
      "source": [
        "## Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsatoVfnXVoS",
        "outputId": "4a63b914-69da-443f-9576-09af57b4a0b5"
      },
      "source": [
        "# Let's create a new folder and download the dataset.\n",
        "! mkdir data\n",
        "! wget -O data/laptops_train.json https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/laptops_train.json\n",
        "! wget -O data/laptops_dev.json https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/laptops_dev.json\n",
        "! wget -O data/restaurants_train.json https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/restaurants_train.json\n",
        "! wget -O data/restaurants_dev.json https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/restaurants_dev.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2021-06-15 20:22:06--  https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/laptops_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 668974 (653K) [text/plain]\n",
            "Saving to: ‘data/laptops_train.json’\n",
            "\n",
            "data/laptops_train. 100%[===================>] 653.29K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-06-15 20:22:06 (22.1 MB/s) - ‘data/laptops_train.json’ saved [668974/668974]\n",
            "\n",
            "--2021-06-15 20:22:07--  https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/laptops_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 148196 (145K) [text/plain]\n",
            "Saving to: ‘data/laptops_dev.json’\n",
            "\n",
            "data/laptops_dev.js 100%[===================>] 144.72K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-06-15 20:22:07 (11.8 MB/s) - ‘data/laptops_dev.json’ saved [148196/148196]\n",
            "\n",
            "--2021-06-15 20:22:07--  https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/restaurants_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1190549 (1.1M) [text/plain]\n",
            "Saving to: ‘data/restaurants_train.json’\n",
            "\n",
            "data/restaurants_tr 100%[===================>]   1.13M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-06-15 20:22:07 (26.2 MB/s) - ‘data/restaurants_train.json’ saved [1190549/1190549]\n",
            "\n",
            "--2021-06-15 20:22:07--  https://raw.githubusercontent.com/SapienzaNLP/nlp2021-hw2/master/data/restaurants_dev.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 259896 (254K) [text/plain]\n",
            "Saving to: ‘data/restaurants_dev.json’\n",
            "\n",
            "data/restaurants_de 100%[===================>] 253.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-06-15 20:22:07 (12.0 MB/s) - ‘data/restaurants_dev.json’ saved [259896/259896]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "NNnJfU69XYDo",
        "outputId": "ffb2f979-f47e-496f-bb42-c943edaf2871"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "\n",
        "root_folder: str = r\"./data\" # to save dataset\n",
        "\n",
        "laptops_train_filename = \"laptops_train.json\"\n",
        "laptops_valid_filename = \"laptops_dev.json\"\n",
        "restaurants_train_filename = \"restaurants_train.json\"\n",
        "restaurants_valid_filename = \"restaurants_dev.json\"\n",
        "\n",
        "laptops_train_dataframe = pd.read_json(os.sep.join([root_folder, laptops_train_filename]), orient='records')\n",
        "laptops_valid_dataframe = pd.read_json(os.sep.join([root_folder, laptops_valid_filename]), orient='records')\n",
        "restaurants_train_dataframe = pd.read_json(os.sep.join([root_folder, restaurants_train_filename]), orient='records')\n",
        "restaurants_valid_dataframe = pd.read_json(os.sep.join([root_folder, restaurants_valid_filename]), orient='records')\n",
        "\n",
        "restaurants_train_dataframe.drop('categories', inplace=True, axis=1)\n",
        "restaurants_valid_dataframe.drop('categories', inplace=True, axis=1)\n",
        "\n",
        "train_dataframe = pd.concat([laptops_train_dataframe, restaurants_train_dataframe], ignore_index=True)\n",
        "valid_dataframe = pd.concat([laptops_valid_dataframe, restaurants_valid_dataframe], ignore_index=True)\n",
        "\n",
        "laptops_train_dataframe = None\n",
        "laptops_valid_dataframe = None\n",
        "restaurants_train_dataframe = None\n",
        "restaurants_valid_dataframe = None\n",
        "\n",
        "VALID_SIZE = len(valid_dataframe)\n",
        "TEST_SIZE = VALID_SIZE\n",
        "\n",
        "train_dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[22, 31], hard disk, neutral]]</td>\n",
              "      <td>I always use a backup hard disk to store impor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[34, 38], size, positive]]</td>\n",
              "      <td>I also love the small, convenient size of my l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[76, 84], mousepad, neutral]]</td>\n",
              "      <td>I thought the white Mac computers looked dirty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[40, 48], responds, positive]]</td>\n",
              "      <td>It is always reliable, never bugged and respon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[55, 63], keyboard, positive], [[73, 78], sp...</td>\n",
              "      <td>The real stand out on this computer is the fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>[]</td>\n",
              "      <td>I actually gave Patroon another chance before ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>[[[77, 84], service, positive], [[123, 128], p...</td>\n",
              "      <td>Although they do the typical what kind of wate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>[]</td>\n",
              "      <td>That said, I thought Scalini Fedeli was one of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>[[[27, 34], waiters, positive], [[125, 131], d...</td>\n",
              "      <td>Have always found that the waiters will go out...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>[[[18, 34], pre-theatre menu, positive]]</td>\n",
              "      <td>If you go for the pre-theatre menu, it's an ev...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                targets                                               text\n",
              "0                      [[[22, 31], hard disk, neutral]]  I always use a backup hard disk to store impor...\n",
              "1                          [[[34, 38], size, positive]]  I also love the small, convenient size of my l...\n",
              "2                       [[[76, 84], mousepad, neutral]]  I thought the white Mac computers looked dirty...\n",
              "3                      [[[40, 48], responds, positive]]  It is always reliable, never bugged and respon...\n",
              "4     [[[55, 63], keyboard, positive], [[73, 78], sp...  The real stand out on this computer is the fee...\n",
              "...                                                 ...                                                ...\n",
              "4995                                                 []  I actually gave Patroon another chance before ...\n",
              "4996  [[[77, 84], service, positive], [[123, 128], p...  Although they do the typical what kind of wate...\n",
              "4997                                                 []  That said, I thought Scalini Fedeli was one of...\n",
              "4998  [[[27, 34], waiters, positive], [[125, 131], d...  Have always found that the waiters will go out...\n",
              "4999           [[[18, 34], pre-theatre menu, positive]]  If you go for the pre-theatre menu, it's an ev...\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "40_kIrMrXkIX",
        "outputId": "2707aafc-c7ef-4145-ec8a-ebd2838cda10"
      },
      "source": [
        "valid_dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[]</td>\n",
              "      <td>It was over rated!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[55, 75], adding the bluetooth, negative]]</td>\n",
              "      <td>But Sony said we could send it back and be cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[4, 21], Windows 7 Starter, positive]]</td>\n",
              "      <td>The Windows 7 Starter is, in my opinion, a gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[4, 14], powerpoint, positive]]</td>\n",
              "      <td>The powerpoint opened seamlessly in the apple ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[74, 80], screen, positive]]</td>\n",
              "      <td>I chose the iBookG4, a laptop that is an attra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081</th>\n",
              "      <td>[]</td>\n",
              "      <td>(or sister, in my case!).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082</th>\n",
              "      <td>[[[0, 5], Staff, positive]]</td>\n",
              "      <td>Staff is very accomodating.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083</th>\n",
              "      <td>[[[26, 40], yellowfun tuna, positive], [[51, 6...</td>\n",
              "      <td>I particularly love their yellowfun tuna and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1084</th>\n",
              "      <td>[]</td>\n",
              "      <td>Enjoy!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1085</th>\n",
              "      <td>[[[18, 24], eating, positive]]</td>\n",
              "      <td>I look forward to eating here again</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1086 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                targets                                               text\n",
              "0                                                    []                                 It was over rated!\n",
              "1          [[[55, 75], adding the bluetooth, negative]]  But Sony said we could send it back and be cha...\n",
              "2              [[[4, 21], Windows 7 Starter, positive]]  The Windows 7 Starter is, in my opinion, a gre...\n",
              "3                     [[[4, 14], powerpoint, positive]]  The powerpoint opened seamlessly in the apple ...\n",
              "4                        [[[74, 80], screen, positive]]  I chose the iBookG4, a laptop that is an attra...\n",
              "...                                                 ...                                                ...\n",
              "1081                                                 []                          (or sister, in my case!).\n",
              "1082                        [[[0, 5], Staff, positive]]                        Staff is very accomodating.\n",
              "1083  [[[26, 40], yellowfun tuna, positive], [[51, 6...  I particularly love their yellowfun tuna and t...\n",
              "1084                                                 []                                             Enjoy!\n",
              "1085                     [[[18, 24], eating, positive]]                I look forward to eating here again\n",
              "\n",
              "[1086 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ5snLkJXn9C"
      },
      "source": [
        "def spans(txt: str) -> List[Tuple[int, int]]:\n",
        "    # This function returns the spans of the several tokens of the input text\n",
        "    tokens = nltk.word_tokenize(txt)\n",
        "    tokens = filter(lambda token: preprocess_term(token) != '', tokens)\n",
        "    offset = 0\n",
        "    spans_list = list()\n",
        "    for token in tokens:\n",
        "        offset = txt.find(token, offset)\n",
        "        spans_list.append((offset, offset+len(token)))\n",
        "        offset += len(token)\n",
        "    return spans_list\n",
        "\n",
        "def preprocess_term(term: str) -> str: # I remove punctuation\n",
        "    # This function is used in order to preprocess a signle tokenized term\n",
        "    cleaned_term = ''\n",
        "    for char in term:\n",
        "      if (char not in punctuation) and (char not in '“”'):\n",
        "        cleaned_term = cleaned_term + char\n",
        "\n",
        "    return cleaned_term\n",
        "\n",
        "def preprocess_text(text: str, start_indexes: List[int], end_indexes: List[int], polarities: List[str]) -> Tuple[List[Dict[str, str]], List[str]]:\n",
        "  # This function returns a list of dicts, where each dict is associated to a tokenized preprocessed term and contains information about the token itslef and its label\n",
        "  preprocessed_text = []\n",
        "  end_indexes.insert(0, 0)\n",
        "  true_aspect_terms = list()\n",
        "  \n",
        "  for i in range(len(start_indexes)):\n",
        "    start_index = start_indexes[i]\n",
        "    end_index = end_indexes[i + 1]\n",
        "    preprocessed_text += list(map(lambda indexes: {'token': text[end_indexes[i] + indexes[0] : end_indexes[i] + indexes[1]], 'ne_label': 'O'}, spans(text[end_indexes[i] : start_index])))\n",
        "    aspect_term = text[start_index:end_index]\n",
        "    true_aspect_terms.append(aspect_term)\n",
        "    aspect_term = aspect_term.split(' ')\n",
        "    aspect_term_list = []\n",
        "    for j in range(len(aspect_term)):\n",
        "      term = aspect_term[j]\n",
        "      preprocessed_term = preprocess_term(term)\n",
        "      if preprocessed_term != '':\n",
        "        d = {'token': preprocessed_term, 'ne_label': 'B-AT' if len(aspect_term_list) == 0 else 'I-AT', 'polarity': polarities[i]}\n",
        "        aspect_term_list.append(d)\n",
        "      start_index += len(term) + 1\n",
        "    preprocessed_text += aspect_term_list\n",
        "  preprocessed_text += list(map(lambda indexes: {'token': text[end_indexes[-1] + indexes[0] : end_indexes[-1] + indexes[1]], 'ne_label': 'O'}, spans(text[end_indexes[-1] : ])))\n",
        "\n",
        "  return preprocessed_text, true_aspect_terms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOm6Is9OT9uH"
      },
      "source": [
        "BERT_MODEL = 'roberta-large'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False, do_basic_tokenize=False) # I have already done the tokenization with the preprocessing function ---> do_basic_tokenize=False\n",
        "\n",
        "class ABSA_B_Dataset(Dataset):\n",
        "\n",
        "    # static variables\n",
        "    polarities = ['positive', 'negative', 'neutral', 'conflict', 'PAD']\n",
        "    polarity2idx = {t: i for i, t in enumerate(polarities)}\n",
        "    padding_polarity_index = polarity2idx['PAD']\n",
        "\n",
        "\n",
        "    def __init__(self, \n",
        "                 targets: pd.Series,\n",
        "                 text: pd.Series,\n",
        "                 preprocess_text: Callable[[str, List[int], List[int]], Tuple[List[Dict[str, str]], List[str]]]=preprocess_text):\n",
        "        \"\"\"\n",
        "        We assume that the dataset can fit in memory.\n",
        "        Args:\n",
        "            targets (pd.Series): Pandas Dataframe column containing the targets.\n",
        "            text (pd.Series): Pandas Dataframe column containing the text.\n",
        "            device (string): device where to put tensors (cpu or cuda).\n",
        "        \"\"\"\n",
        "\n",
        "        self.data = []\n",
        "        for row_targets, row_text in zip(targets, text):\n",
        "          indexes_and_polarities = list()\n",
        "          for target in row_targets:\n",
        "            indexes = target[0]\n",
        "            indexes_and_polarities.append((indexes[0], indexes[1], target[2]))\n",
        "          indexes_and_polarities.sort()\n",
        "          start_indexes, end_indexes, polarities = [elem[0] for elem in indexes_and_polarities], [elem[1] for elem in indexes_and_polarities], [elem[2] for elem in indexes_and_polarities]\n",
        "          preprocessed_text, true_aspect_terms = preprocess_text(row_text, start_indexes, end_indexes, polarities)\n",
        "          assert len(true_aspect_terms) == len(polarities)\n",
        "\n",
        "          self.data.append({\"preprocessed_text\": preprocessed_text,\n",
        "                            \"true_outputs\": {'targets': list(zip(true_aspect_terms, polarities))}})\n",
        "        self.encoded_data = None\n",
        "    \n",
        "    def index_dataset(self):\n",
        "        self.encoded_data = list()\n",
        "        for i in range(len(self.data)):\n",
        "            # for each sentence\n",
        "            data_i = self.data[i]\n",
        "            elem = data_i[\"preprocessed_text\"]\n",
        "            encoded_elem, encoded_labels, start_indexes, end_indexes = self.encode_text_and_labels(elem)\n",
        "            true_outputs = data_i[\"true_outputs\"]\n",
        "            assert len(encoded_labels) == len(true_outputs['targets'])\n",
        "\n",
        "            self.encoded_data.append({\"inputs\": encoded_elem, \n",
        "                                      \"outputs\": encoded_labels,\n",
        "                                      \"start_indexes\": start_indexes,\n",
        "                                      \"end_indexes\": end_indexes,\n",
        "                                      \"true_outputs\": true_outputs})\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.encoded_data is None:\n",
        "            raise RuntimeError(\"\"\"Trying to retrieve elements but index_dataset\n",
        "            has not been invoked yet! Be sure to invoce index_dataset on this object\n",
        "            before trying to retrieve elements. In case you want to retrieve raw\n",
        "            elements, use the method get_raw_element(idx)\"\"\")\n",
        "        return self.encoded_data[idx]\n",
        "    \n",
        "    def get_raw_element(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_text_and_labels(sentence:list):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (list): list of Dicts, each carrying the information about\n",
        "            one token.\n",
        "        Return:\n",
        "            The method returns four lists of indexes corresponding to the input tokens, input labels, start indexes and end indexes of word pieces of aspect terms in the input sentence\n",
        "        \"\"\"\n",
        "\n",
        "        words_pieces_list, polarity_indexes, start_indexes, end_indexes = [tokenizer.bos_token], list(), list(), list()\n",
        "\n",
        "        for i, d in enumerate(sentence):\n",
        "\n",
        "          word = d['token']\n",
        "          label = d['ne_label']\n",
        "          \n",
        "          tokens = tokenizer.tokenize(word, is_split_into_words = i != 0) # The Ġ char should not be added at the first word of the sentence\n",
        "          n_word_pieces = len(tokens)\n",
        "\n",
        "          word_pieces_without_punct = list()\n",
        "          add_special_symbol = False\n",
        "\n",
        "          for word_piece_index, word_piece in enumerate(tokens):\n",
        "            filtered_word_pieces = word_piece.replace('Ġ', '')\n",
        "            if filtered_word_pieces not in punctuation:\n",
        "              if add_special_symbol:\n",
        "                new_word_pieces = tokenizer.tokenize(word_piece, is_split_into_words = i != 0)\n",
        "                word_pieces_without_punct.extend(new_word_pieces)\n",
        "                add_special_symbol = False\n",
        "              else:\n",
        "                word_pieces_without_punct.append(word_piece)\n",
        "            elif word_piece_index == 0:\n",
        "              add_special_symbol = True\n",
        "\n",
        "          if label == 'B-AT':\n",
        "            start_indexes.append(len(words_pieces_list))\n",
        "            polarity_indexes.append(ABSA_B_Dataset.polarity2idx[d['polarity']])\n",
        "\n",
        "          words_pieces_list.extend(word_pieces_without_punct if len(word_pieces_without_punct) > 0 else tokens)\n",
        "\n",
        "          if label == 'B-AT':\n",
        "            end_indexes.append(len(words_pieces_list) - 1)\n",
        "          elif label == 'I-AT':\n",
        "            end_indexes[-1] = len(words_pieces_list) - 1\n",
        "              \n",
        "\n",
        "        words_pieces_list.append(tokenizer.eos_token)\n",
        "\n",
        "        assert len(start_indexes) == len(end_indexes) == len(polarity_indexes)\n",
        "\n",
        "        return torch.LongTensor(tokenizer.convert_tokens_to_ids(words_pieces_list)), torch.LongTensor(polarity_indexes), torch.LongTensor(start_indexes), torch.LongTensor(end_indexes)\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def decode_output(max_indices:List[List[int]]):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_indices: a List where the i-th entry is a List containing the\n",
        "            indexes preds for the i-th sample\n",
        "        Output:\n",
        "            The method returns a list of batch_size length where each element is a list\n",
        "            of labels, one for each input token.\n",
        "        \"\"\"\n",
        "        predictions = list()\n",
        "        for indices in max_indices:\n",
        "            predictions.append([ABSA_B_Dataset.polarities[i] for i in indices])\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQM4Mkdf4cjs"
      },
      "source": [
        "from math import sqrt\n",
        "\n",
        "def get_polarities_weights(train_polarities_count: pd.Series):\n",
        "  \n",
        "  if VARIANT_TO_TEST == 'INS':\n",
        "\n",
        "    weights = 1.0 / np.array(train_polarities_count)\n",
        "    weights = weights / np.sum(weights) * len(train_polarities_count)\n",
        "    weights = np.append(weights, 0) # weight for the PAD polarity\n",
        "\n",
        "  elif VARIANT_TO_TEST == 'ISNS':\n",
        "\n",
        "    weights = np.sqrt(1.0 / np.array(train_polarities_count))\n",
        "    weights = weights / np.sum(weights) * len(train_polarities_count)\n",
        "    weights = np.append(weights, 0)\n",
        "\n",
        "  elif VARIANT_TO_TEST == 'ENS':\n",
        "\n",
        "    beta = 0.9999\n",
        "    effective_num = 1.0 - np.power(beta, train_polarities_count)\n",
        "    weights = (1.0 - beta) / np.array(effective_num)\n",
        "    weights = weights / np.sum(weights) * len(train_polarities_count)\n",
        "    weights = np.append(weights, 0)\n",
        "\n",
        "  elif VARIANT_TO_TEST == 'ATPC':\n",
        "\n",
        "    max_polarity_count = max(train_polarities_count)\n",
        "    weights = [max_polarity_count / train_polarities_count[polarity] for polarity in ABSA_B_Dataset.polarities if polarity != 'PAD'] + [0]\n",
        "\n",
        "  else:\n",
        "\n",
        "    max_polarity_count = max(train_polarities_count)\n",
        "    weights = [sqrt(max_polarity_count / train_polarities_count[polarity]) for polarity in ABSA_B_Dataset.polarities if polarity != 'PAD'] + [0]\n",
        "\n",
        "  return torch.FloatTensor(weights)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "MXNzb5fR18Hi",
        "outputId": "4c9f2418-1f7f-4a9a-df70-6faf571f1767"
      },
      "source": [
        "train_polarities_count = pd.Series([target[-1] for row_targets in train_dataframe.targets for target in row_targets], name='train polarities').value_counts()\n",
        "train_polarities_count.to_frame().style.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row0_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 100.0%, transparent 100.0%);\n",
              "        }#T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row1_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 50.2%, transparent 50.2%);\n",
              "        }#T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row2_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 30.7%, transparent 30.7%);\n",
              "        }#T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row3_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "        }</style><table id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >train polarities</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >positive</th>\n",
              "                        <td id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row0_col0\" class=\"data row0 col0\" >2605</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >negative</th>\n",
              "                        <td id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row1_col0\" class=\"data row1 col0\" >1364</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >neutral</th>\n",
              "                        <td id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row2_col0\" class=\"data row2 col0\" >877</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >conflict</th>\n",
              "                        <td id=\"T_5cd73abe_ce17_11eb_8d49_0242ac1c0002row3_col0\" class=\"data row3 col0\" >111</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f774c8a7310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brj7lcbc85Ey",
        "outputId": "335549d0-3228-4aa7-fc36-10a75a84f3dd"
      },
      "source": [
        "POLARITIES_WEIGHTS = get_polarities_weights(train_polarities_count)\n",
        "POLARITIES_WEIGHTS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.3820, 1.7235, 4.8444, 0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "zsXAysXq18u0",
        "outputId": "8d45b1ee-57bd-4f55-ea7b-7d1a3d4aee53"
      },
      "source": [
        "pd.Series([target[-1] for row_targets in valid_dataframe.targets for target in row_targets], name='valid polarities').value_counts().to_frame().style.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row0_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 100.0%, transparent 100.0%);\n",
              "        }#T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row1_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 54.1%, transparent 54.1%);\n",
              "        }#T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row2_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "            background:  linear-gradient(90deg,#d65f5f 36.7%, transparent 36.7%);\n",
              "        }#T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row3_col0{\n",
              "            width:  10em;\n",
              "             height:  80%;\n",
              "        }</style><table id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >valid polarities</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >positive</th>\n",
              "                        <td id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row0_col0\" class=\"data row0 col0\" >546</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >negative</th>\n",
              "                        <td id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row1_col0\" class=\"data row1 col0\" >307</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >neutral</th>\n",
              "                        <td id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row2_col0\" class=\"data row2 col0\" >216</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >conflict</th>\n",
              "                        <td id=\"T_5cdcbc64_ce17_11eb_8d49_0242ac1c0002row3_col0\" class=\"data row3 col0\" >25</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f7754038ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSV7kQ4g4VEh",
        "outputId": "1149ebab-44a5-477e-a415-e7c542f8bcf1"
      },
      "source": [
        "def test_dataset_class():\n",
        "\n",
        "    dataset = ABSA_B_Dataset(train_dataframe['targets'], train_dataframe['text'])\n",
        "    \n",
        "    print('Dataset test:')\n",
        "    for i in range(10):\n",
        "        print('  sample {}: {}'.format(i, [\"Token: \" + t[\"token\"] + \", NE label: \" +  t[\"ne_label\"] + \", polarity: \" + t.get('polarity', '') for t in dataset.get_raw_element(i)['preprocessed_text']]))\n",
        "    dataset = None\n",
        "\n",
        "test_dataset_class()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset test:\n",
            "  sample 0: ['Token: I, NE label: O, polarity: ', 'Token: always, NE label: O, polarity: ', 'Token: use, NE label: O, polarity: ', 'Token: a, NE label: O, polarity: ', 'Token: backup, NE label: O, polarity: ', 'Token: hard, NE label: B-AT, polarity: neutral', 'Token: disk, NE label: I-AT, polarity: neutral', 'Token: to, NE label: O, polarity: ', 'Token: store, NE label: O, polarity: ', 'Token: important, NE label: O, polarity: ', 'Token: files, NE label: O, polarity: ', 'Token: at, NE label: O, polarity: ', 'Token: all, NE label: O, polarity: ', 'Token: times, NE label: O, polarity: ']\n",
            "  sample 1: ['Token: I, NE label: O, polarity: ', 'Token: also, NE label: O, polarity: ', 'Token: love, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: small, NE label: O, polarity: ', 'Token: convenient, NE label: O, polarity: ', 'Token: size, NE label: B-AT, polarity: positive', 'Token: of, NE label: O, polarity: ', 'Token: my, NE label: O, polarity: ', 'Token: laptop, NE label: O, polarity: ', 'Token: making, NE label: O, polarity: ', 'Token: it, NE label: O, polarity: ', 'Token: a, NE label: O, polarity: ', 'Token: perfect, NE label: O, polarity: ', 'Token: tool, NE label: O, polarity: ', 'Token: for, NE label: O, polarity: ', 'Token: my, NE label: O, polarity: ', 'Token: academic, NE label: O, polarity: ', 'Token: studies, NE label: O, polarity: ']\n",
            "  sample 2: ['Token: I, NE label: O, polarity: ', 'Token: thought, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: white, NE label: O, polarity: ', 'Token: Mac, NE label: O, polarity: ', 'Token: computers, NE label: O, polarity: ', 'Token: looked, NE label: O, polarity: ', 'Token: dirty, NE label: O, polarity: ', 'Token: too, NE label: O, polarity: ', 'Token: quicly, NE label: O, polarity: ', 'Token: where, NE label: O, polarity: ', 'Token: you, NE label: O, polarity: ', 'Token: use, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: mousepad, NE label: B-AT, polarity: neutral', 'Token: and, NE label: O, polarity: ', 'Token: where, NE label: O, polarity: ', 'Token: you, NE label: O, polarity: ', 'Token: place, NE label: O, polarity: ', 'Token: your, NE label: O, polarity: ', 'Token: hands, NE label: O, polarity: ', 'Token: when, NE label: O, polarity: ', 'Token: typing, NE label: O, polarity: ']\n",
            "  sample 3: ['Token: It, NE label: O, polarity: ', 'Token: is, NE label: O, polarity: ', 'Token: always, NE label: O, polarity: ', 'Token: reliable, NE label: O, polarity: ', 'Token: never, NE label: O, polarity: ', 'Token: bugged, NE label: O, polarity: ', 'Token: and, NE label: O, polarity: ', 'Token: responds, NE label: B-AT, polarity: positive', 'Token: well, NE label: O, polarity: ']\n",
            "  sample 4: ['Token: The, NE label: O, polarity: ', 'Token: real, NE label: O, polarity: ', 'Token: stand, NE label: O, polarity: ', 'Token: out, NE label: O, polarity: ', 'Token: on, NE label: O, polarity: ', 'Token: this, NE label: O, polarity: ', 'Token: computer, NE label: O, polarity: ', 'Token: is, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: feel, NE label: O, polarity: ', 'Token: of, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: keyboard, NE label: B-AT, polarity: positive', 'Token: and, NE label: O, polarity: ', 'Token: it, NE label: O, polarity: ', \"Token: 's, NE label: O, polarity: \", 'Token: speed, NE label: B-AT, polarity: positive']\n",
            "  sample 5: ['Token: -Called, NE label: O, polarity: ', 'Token: headquarters, NE label: O, polarity: ', 'Token: again, NE label: O, polarity: ', 'Token: they, NE label: O, polarity: ', 'Token: report, NE label: O, polarity: ', 'Token: that, NE label: O, polarity: ', 'Token: TFT, NE label: B-AT, polarity: negative', 'Token: panel, NE label: I-AT, polarity: negative', 'Token: is, NE label: O, polarity: ', 'Token: broken, NE label: O, polarity: ', 'Token: should, NE label: O, polarity: ', 'Token: be, NE label: O, polarity: ', 'Token: fixed, NE label: O, polarity: ', 'Token: by, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: end, NE label: O, polarity: ', 'Token: of, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: week, NE label: O, polarity: ', 'Token: week, NE label: O, polarity: ', 'Token: 3, NE label: O, polarity: ']\n",
            "  sample 6: ['Token: This, NE label: O, polarity: ', 'Token: computer, NE label: O, polarity: ', 'Token: was, NE label: O, polarity: ', 'Token: bought, NE label: O, polarity: ', 'Token: because, NE label: O, polarity: ', 'Token: I, NE label: O, polarity: ', 'Token: wanted, NE label: O, polarity: ', 'Token: top, NE label: O, polarity: ', 'Token: of, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: line, NE label: O, polarity: ', 'Token: fast, NE label: O, polarity: ', 'Token: reliable, NE label: O, polarity: ', 'Token: HA, NE label: O, polarity: ']\n",
            "  sample 7: ['Token: I, NE label: O, polarity: ', 'Token: decided, NE label: O, polarity: ', 'Token: I, NE label: O, polarity: ', 'Token: wanted, NE label: O, polarity: ', 'Token: a, NE label: O, polarity: ', 'Token: laptop, NE label: O, polarity: ', 'Token: so, NE label: O, polarity: ', 'Token: I, NE label: O, polarity: ', 'Token: went, NE label: O, polarity: ', 'Token: into, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: BBY, NE label: O, polarity: ', 'Token: store, NE label: O, polarity: ']\n",
            "  sample 8: ['Token: Since, NE label: O, polarity: ', 'Token: I, NE label: O, polarity: ', 'Token: never, NE label: O, polarity: ', 'Token: really, NE label: O, polarity: ', 'Token: got, NE label: O, polarity: ', 'Token: to, NE label: O, polarity: ', 'Token: use, NE label: O, polarity: ', 'Token: this, NE label: O, polarity: ', 'Token: I, NE label: O, polarity: ', 'Token: ca, NE label: O, polarity: ', \"Token: n't, NE label: O, polarity: \", 'Token: comment, NE label: O, polarity: ', 'Token: on, NE label: O, polarity: ', 'Token: anything, NE label: O, polarity: ', 'Token: except, NE label: O, polarity: ', 'Token: what, NE label: O, polarity: ', 'Token: went, NE label: O, polarity: ', 'Token: wrong, NE label: O, polarity: ', 'Token: after, NE label: O, polarity: ', 'Token: trying, NE label: O, polarity: ', 'Token: 2, NE label: O, polarity: ', 'Token: of, NE label: O, polarity: ', 'Token: them, NE label: O, polarity: ']\n",
            "  sample 9: ['Token: Sometimes, NE label: O, polarity: ', 'Token: you, NE label: O, polarity: ', 'Token: really, NE label: O, polarity: ', 'Token: have, NE label: O, polarity: ', 'Token: to, NE label: O, polarity: ', 'Token: tap, NE label: O, polarity: ', 'Token: the, NE label: O, polarity: ', 'Token: pad, NE label: B-AT, polarity: negative', 'Token: to, NE label: O, polarity: ', 'Token: get, NE label: O, polarity: ', 'Token: it, NE label: O, polarity: ', 'Token: to, NE label: O, polarity: ', 'Token: worki, NE label: O, polarity: ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1YqEu2q5ntU"
      },
      "source": [
        "dataset = ABSA_B_Dataset(train_dataframe['targets'], train_dataframe['text'])\n",
        "dataset.index_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM0fp9zr7GV3"
      },
      "source": [
        "def rnn_collate_fn(\n",
        "    data_elements: List[Dict[str, Union[torch.Tensor, List]]]) -> List[Dict[str, Union[torch.Tensor, List]]]:\n",
        "\n",
        "    X, Y = [de['inputs'] for de in data_elements], [de['outputs'] for de in data_elements] # lists of index tensors\n",
        "    start_indexes, end_indexes = [de['start_indexes'] for de in data_elements], [de['end_indexes'] for de in data_elements] # lists of index tensors\n",
        "    \n",
        "    batch = {}\n",
        "    padding_token_id = tokenizer.pad_token_id\n",
        "    padding_polarity_index = ABSA_B_Dataset.padding_polarity_index\n",
        "    batch['inputs'] = pad_sequence(X, batch_first=True, padding_value=padding_token_id)\n",
        "    batch['outputs'] = pad_sequence(Y, batch_first=True, padding_value=padding_polarity_index)\n",
        "    batch['start_indexes'] = pad_sequence(start_indexes, batch_first=True, padding_value=0)\n",
        "    batch['end_indexes'] = pad_sequence(end_indexes, batch_first=True, padding_value=0)\n",
        "    batch['true_outputs'] = [de['true_outputs'] for de in data_elements]\n",
        "    batch['attention_masks'] = torch.tensor([[int(index != padding_token_id) for index in input_sample] for input_sample in batch['inputs']])\n",
        "    batch['label_masks'] = torch.tensor([[POLARITIES_WEIGHTS[index] for index in output_sample] for output_sample in batch['outputs']])\n",
        "\n",
        "\n",
        "    assert batch['inputs'].shape == batch['attention_masks'].shape and batch['outputs'].shape == batch['start_indexes'].shape == batch['end_indexes'].shape == batch['label_masks'].shape\n",
        "    \n",
        "    return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ7V_-Li-B6W"
      },
      "source": [
        "class DataModuleABSA_B(pl.LightningDataModule):\n",
        "    def __init__(self, training_targets, training_text, dev_targets, dev_text, batch_size=32, number_of_valid_samples=VALID_SIZE, number_of_test_samples=TEST_SIZE):\n",
        "        super().__init__()\n",
        "        self.training_targets = training_targets\n",
        "        self.training_text = training_text\n",
        "        self.dev_targets = dev_targets\n",
        "        self.dev_text = dev_text\n",
        "        self.batch_size = batch_size\n",
        "        self.number_of_valid_samples = number_of_valid_samples\n",
        "        self.number_of_test_samples = number_of_test_samples\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "      self.trainingset = ABSA_B_Dataset(self.training_targets, self.training_text)\n",
        "      self.devset = ABSA_B_Dataset(self.dev_targets, self.dev_text)\n",
        "      self.testset = ABSA_B_Dataset(self.dev_targets, self.dev_text)\n",
        "\n",
        "      self.trainingset.index_dataset()\n",
        "      self.devset.index_dataset()\n",
        "      self.testset.index_dataset()\n",
        "          \n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.trainingset,\n",
        "                        batch_size=self.batch_size,\n",
        "                        shuffle=True,\n",
        "                        collate_fn=rnn_collate_fn,\n",
        "                        num_workers=0)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.devset,\n",
        "                          batch_size=self.number_of_valid_samples//2, # If you want to test with the last four layers ---> //4, because, otherwise, the CUDA memory is not sufficient\n",
        "                          shuffle=False,\n",
        "                          collate_fn=rnn_collate_fn,\n",
        "                          num_workers=0)\n",
        "    \n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.testset,\n",
        "                          batch_size=self.number_of_test_samples//2,\n",
        "                          shuffle=False,\n",
        "                          collate_fn=rnn_collate_fn,\n",
        "                          num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZENCLSm-hVX",
        "outputId": "78fd34da-a1c2-4b26-c6fd-6fb20a2dded6"
      },
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=32, collate_fn=rnn_collate_fn)\n",
        "for batch in train_dataloader:\n",
        "    print(batch['inputs'])\n",
        "    print(batch['outputs'])\n",
        "    print(batch['start_indexes'])\n",
        "    print(batch['end_indexes'])\n",
        "    print(batch['true_outputs'])\n",
        "    print(batch['attention_masks'])\n",
        "    print(batch['label_masks'])\n",
        "    print(batch['inputs'].shape)\n",
        "    print(batch['outputs'].shape)\n",
        "    print(batch['start_indexes'].shape)\n",
        "    print(batch['end_indexes'].shape)\n",
        "    print(len(batch['true_outputs']))\n",
        "    print(batch['attention_masks'].shape)\n",
        "    print(batch['label_masks'].shape)\n",
        "    for (indexes, mask_values, start_indexes, end_indexes, polarities, label_mask) in zip(batch['inputs'], batch['attention_masks'], batch['start_indexes'], batch['end_indexes'], batch['outputs'], batch['label_masks']):\n",
        "      print(list(zip(tokenizer.convert_ids_to_tokens(indexes), mask_values)))\n",
        "      print(list(zip(start_indexes, end_indexes, polarities, label_mask)))\n",
        "      print('\\n')\n",
        "    break\n",
        "\n",
        "dataset = None # To free up RAM\n",
        "train_dataloader = None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[    0,   100,   460,  ...,     1,     1,     1],\n",
            "        [    0,   100,    67,  ...,     1,     1,     1],\n",
            "        [    0,   100,   802,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0, 34647,   615,  ...,     1,     1,     1],\n",
            "        [    0,  2409,    38,  ...,     1,     1,     1],\n",
            "        [    0,   133,  2332,  ...,     1,     1,     1]])\n",
            "tensor([[2, 4, 4],\n",
            "        [0, 4, 4],\n",
            "        [2, 4, 4],\n",
            "        [0, 4, 4],\n",
            "        [0, 0, 4],\n",
            "        [1, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [1, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [1, 4, 4],\n",
            "        [0, 0, 2],\n",
            "        [0, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [0, 0, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [2, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [0, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [1, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [0, 4, 4],\n",
            "        [4, 4, 4],\n",
            "        [1, 4, 4]])\n",
            "tensor([[ 6,  0,  0],\n",
            "        [ 7,  0,  0],\n",
            "        [17,  0,  0],\n",
            "        [ 9,  0,  0],\n",
            "        [13, 17,  0],\n",
            "        [ 8,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 8,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 4,  0,  0],\n",
            "        [10, 13, 18],\n",
            "        [15,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 8, 17,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 9,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [31,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [12,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 2,  0,  0]])\n",
            "tensor([[ 7,  0,  0],\n",
            "        [ 7,  0,  0],\n",
            "        [18,  0,  0],\n",
            "        [ 9,  0,  0],\n",
            "        [13, 17,  0],\n",
            "        [10,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 8,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 4,  0,  0],\n",
            "        [10, 14, 21],\n",
            "        [16,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 9, 17,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 9,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 7,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [33,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [12,  0,  0],\n",
            "        [ 0,  0,  0],\n",
            "        [ 2,  0,  0]])\n",
            "[{'targets': [('hard disk', 'neutral')]}, {'targets': [('size', 'positive')]}, {'targets': [('mousepad', 'neutral')]}, {'targets': [('responds', 'positive')]}, {'targets': [('keyboard', 'positive'), ('speed', 'positive')]}, {'targets': [('TFT panel', 'negative')]}, {'targets': []}, {'targets': []}, {'targets': []}, {'targets': [('pad', 'negative')]}, {'targets': []}, {'targets': [('hardware', 'negative')]}, {'targets': [('specs', 'positive'), ('aluminum style', 'positive'), ('nvidia 9800', 'neutral')]}, {'targets': [('battery life', 'positive')]}, {'targets': []}, {'targets': []}, {'targets': [('twin packing', 'positive'), ('functions', 'positive')]}, {'targets': []}, {'targets': []}, {'targets': [('features', 'neutral')]}, {'targets': []}, {'targets': []}, {'targets': [('costing', 'positive')]}, {'targets': []}, {'targets': []}, {'targets': []}, {'targets': [('warrenty', 'negative')]}, {'targets': []}, {'targets': []}, {'targets': [('carry', 'positive')]}, {'targets': []}, {'targets': [('display', 'negative')]}]\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "tensor([[1.7235, 0.0000, 0.0000],\n",
            "        [1.0000, 0.0000, 0.0000],\n",
            "        [1.7235, 0.0000, 0.0000],\n",
            "        [1.0000, 0.0000, 0.0000],\n",
            "        [1.0000, 1.0000, 0.0000],\n",
            "        [1.3820, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.3820, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.3820, 0.0000, 0.0000],\n",
            "        [1.0000, 1.0000, 1.7235],\n",
            "        [1.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.0000, 1.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.7235, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.3820, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000],\n",
            "        [1.3820, 0.0000, 0.0000]])\n",
            "torch.Size([32, 44])\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32, 3])\n",
            "torch.Size([32, 3])\n",
            "32\n",
            "torch.Size([32, 44])\n",
            "torch.Size([32, 3])\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġalways', tensor(1)), ('Ġuse', tensor(1)), ('Ġa', tensor(1)), ('Ġbackup', tensor(1)), ('Ġhard', tensor(1)), ('Ġdisk', tensor(1)), ('Ġto', tensor(1)), ('Ġstore', tensor(1)), ('Ġimportant', tensor(1)), ('Ġfiles', tensor(1)), ('Ġat', tensor(1)), ('Ġall', tensor(1)), ('Ġtimes', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(6), tensor(7), tensor(2), tensor(1.7235)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġalso', tensor(1)), ('Ġlove', tensor(1)), ('Ġthe', tensor(1)), ('Ġsmall', tensor(1)), ('Ġconvenient', tensor(1)), ('Ġsize', tensor(1)), ('Ġof', tensor(1)), ('Ġmy', tensor(1)), ('Ġlaptop', tensor(1)), ('Ġmaking', tensor(1)), ('Ġit', tensor(1)), ('Ġa', tensor(1)), ('Ġperfect', tensor(1)), ('Ġtool', tensor(1)), ('Ġfor', tensor(1)), ('Ġmy', tensor(1)), ('Ġacademic', tensor(1)), ('Ġstudies', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(7), tensor(7), tensor(0), tensor(1.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġthought', tensor(1)), ('Ġthe', tensor(1)), ('Ġwhite', tensor(1)), ('ĠMac', tensor(1)), ('Ġcomputers', tensor(1)), ('Ġlooked', tensor(1)), ('Ġdirty', tensor(1)), ('Ġtoo', tensor(1)), ('Ġqu', tensor(1)), ('ic', tensor(1)), ('ly', tensor(1)), ('Ġwhere', tensor(1)), ('Ġyou', tensor(1)), ('Ġuse', tensor(1)), ('Ġthe', tensor(1)), ('Ġmouse', tensor(1)), ('pad', tensor(1)), ('Ġand', tensor(1)), ('Ġwhere', tensor(1)), ('Ġyou', tensor(1)), ('Ġplace', tensor(1)), ('Ġyour', tensor(1)), ('Ġhands', tensor(1)), ('Ġwhen', tensor(1)), ('Ġtyping', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(17), tensor(18), tensor(2), tensor(1.7235)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('It', tensor(1)), ('Ġis', tensor(1)), ('Ġalways', tensor(1)), ('Ġreliable', tensor(1)), ('Ġnever', tensor(1)), ('Ġbu', tensor(1)), ('gged', tensor(1)), ('Ġand', tensor(1)), ('Ġresponds', tensor(1)), ('Ġwell', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(9), tensor(9), tensor(0), tensor(1.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('The', tensor(1)), ('Ġreal', tensor(1)), ('Ġstand', tensor(1)), ('Ġout', tensor(1)), ('Ġon', tensor(1)), ('Ġthis', tensor(1)), ('Ġcomputer', tensor(1)), ('Ġis', tensor(1)), ('Ġthe', tensor(1)), ('Ġfeel', tensor(1)), ('Ġof', tensor(1)), ('Ġthe', tensor(1)), ('Ġkeyboard', tensor(1)), ('Ġand', tensor(1)), ('Ġit', tensor(1)), ('Ġs', tensor(1)), ('Ġspeed', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(13), tensor(13), tensor(0), tensor(1.)), (tensor(17), tensor(17), tensor(0), tensor(1.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('C', tensor(1)), ('alled', tensor(1)), ('Ġheadquarters', tensor(1)), ('Ġagain', tensor(1)), ('Ġthey', tensor(1)), ('Ġreport', tensor(1)), ('Ġthat', tensor(1)), ('ĠT', tensor(1)), ('FT', tensor(1)), ('Ġpanel', tensor(1)), ('Ġis', tensor(1)), ('Ġbroken', tensor(1)), ('Ġshould', tensor(1)), ('Ġbe', tensor(1)), ('Ġfixed', tensor(1)), ('Ġby', tensor(1)), ('Ġthe', tensor(1)), ('Ġend', tensor(1)), ('Ġof', tensor(1)), ('Ġthe', tensor(1)), ('Ġweek', tensor(1)), ('Ġweek', tensor(1)), ('Ġ3', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(8), tensor(10), tensor(1), tensor(1.3820)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('This', tensor(1)), ('Ġcomputer', tensor(1)), ('Ġwas', tensor(1)), ('Ġbought', tensor(1)), ('Ġbecause', tensor(1)), ('ĠI', tensor(1)), ('Ġwanted', tensor(1)), ('Ġtop', tensor(1)), ('Ġof', tensor(1)), ('Ġthe', tensor(1)), ('Ġline', tensor(1)), ('Ġfast', tensor(1)), ('Ġreliable', tensor(1)), ('ĠHA', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġdecided', tensor(1)), ('ĠI', tensor(1)), ('Ġwanted', tensor(1)), ('Ġa', tensor(1)), ('Ġlaptop', tensor(1)), ('Ġso', tensor(1)), ('ĠI', tensor(1)), ('Ġwent', tensor(1)), ('Ġinto', tensor(1)), ('Ġthe', tensor(1)), ('ĠBB', tensor(1)), ('Y', tensor(1)), ('Ġstore', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('Since', tensor(1)), ('ĠI', tensor(1)), ('Ġnever', tensor(1)), ('Ġreally', tensor(1)), ('Ġgot', tensor(1)), ('Ġto', tensor(1)), ('Ġuse', tensor(1)), ('Ġthis', tensor(1)), ('ĠI', tensor(1)), ('Ġca', tensor(1)), ('Ġn', tensor(1)), (\"'t\", tensor(1)), ('Ġcomment', tensor(1)), ('Ġon', tensor(1)), ('Ġanything', tensor(1)), ('Ġexcept', tensor(1)), ('Ġwhat', tensor(1)), ('Ġwent', tensor(1)), ('Ġwrong', tensor(1)), ('Ġafter', tensor(1)), ('Ġtrying', tensor(1)), ('Ġ2', tensor(1)), ('Ġof', tensor(1)), ('Ġthem', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('Sometimes', tensor(1)), ('Ġyou', tensor(1)), ('Ġreally', tensor(1)), ('Ġhave', tensor(1)), ('Ġto', tensor(1)), ('Ġtap', tensor(1)), ('Ġthe', tensor(1)), ('Ġpad', tensor(1)), ('Ġto', tensor(1)), ('Ġget', tensor(1)), ('Ġit', tensor(1)), ('Ġto', tensor(1)), ('Ġwork', tensor(1)), ('i', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(8), tensor(8), tensor(1), tensor(1.3820)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('This', tensor(1)), ('Ġmachine', tensor(1)), ('Ġdelivers', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('Now', tensor(1)), ('Ġfor', tensor(1)), ('Ġthe', tensor(1)), ('Ġhardware', tensor(1)), ('Ġproblems', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(4), tensor(4), tensor(1), tensor(1.3820)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġpreviously', tensor(1)), ('Ġpurchased', tensor(1)), ('Ġa', tensor(1)), ('Ġ13', tensor(1)), ('Ġmac', tensor(1)), ('book', tensor(1)), ('Ġhad', tensor(1)), ('Ġpro', tensor(1)), ('Ġspecs', tensor(1)), ('Ġand', tensor(1)), ('Ġwas', tensor(1)), ('Ġaluminum', tensor(1)), ('Ġstyle', tensor(1)), ('Ġwhich', tensor(1)), ('Ġhad', tensor(1)), ('Ġa', tensor(1)), ('Ġn', tensor(1)), ('vidia', tensor(1)), ('Ġ9', tensor(1)), ('800', tensor(1)), ('ĠIf', tensor(1)), ('ĠI', tensor(1)), ('Ġam', tensor(1)), ('Ġnot', tensor(1)), ('Ġmistaken', tensor(1)), ('Ġand', tensor(1)), ('Ġit', tensor(1)), ('Ġhad', tensor(1)), ('Ġmajor', tensor(1)), ('Ġheating', tensor(1)), ('Ġissues', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(10), tensor(10), tensor(0), tensor(1.)), (tensor(13), tensor(14), tensor(0), tensor(1.)), (tensor(18), tensor(21), tensor(2), tensor(1.7235))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġwould', tensor(1)), ('Ġrecommend', tensor(1)), ('Ġthis', tensor(1)), ('Ġcomputer', tensor(1)), ('Ġto', tensor(1)), ('Ġanyone', tensor(1)), ('Ġsearching', tensor(1)), ('Ġfor', tensor(1)), ('Ġthe', tensor(1)), ('Ġperfect', tensor(1)), ('Ġlaptop', tensor(1)), ('Ġand', tensor(1)), ('Ġthe', tensor(1)), ('Ġbattery', tensor(1)), ('Ġlife', tensor(1)), ('Ġis', tensor(1)), ('Ġamazing', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(15), tensor(16), tensor(0), tensor(1.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('Oh', tensor(1)), ('Ġboy', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġhave', tensor(1)), ('Ġhad', tensor(1)), ('Ġno', tensor(1)), ('Ġluck', tensor(1)), ('Ġwith', tensor(1)), ('Ġstaples', tensor(1)), ('Ġor', tensor(1)), ('ĠHP', tensor(1)), ('Ġto', tensor(1)), ('Ġresolve', tensor(1)), ('Ġthis', tensor(1)), ('Ġproblem', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('The', tensor(1)), ('ĠMac', tensor(1)), ('book', tensor(1)), ('Ġarrived', tensor(1)), ('Ġin', tensor(1)), ('Ġa', tensor(1)), ('Ġnice', tensor(1)), ('Ġtwin', tensor(1)), ('Ġpacking', tensor(1)), ('Ġand', tensor(1)), ('Ġsealed', tensor(1)), ('Ġin', tensor(1)), ('Ġthe', tensor(1)), ('Ġbox', tensor(1)), ('Ġall', tensor(1)), ('Ġthe', tensor(1)), ('Ġfunctions', tensor(1)), ('Ġworks', tensor(1)), ('Ġgreat', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(8), tensor(9), tensor(0), tensor(1.)), (tensor(17), tensor(17), tensor(0), tensor(1.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('It', tensor(1)), ('Ġallows', tensor(1)), ('Ġyou', tensor(1)), ('Ġto', tensor(1)), ('Ġautomatically', tensor(1)), ('Ġupload', tensor(1)), ('Ġphotos', tensor(1)), ('Ġto', tensor(1)), ('Ġyour', tensor(1)), ('ĠFacebook', tensor(1)), ('Ġaccount', tensor(1)), ('Ġwith', tensor(1)), ('Ġone', tensor(1)), ('Ġclick', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('If', tensor(1)), ('Ġyou', tensor(1)), ('Ġare', tensor(1)), ('Ġlooking', tensor(1)), ('Ġfor', tensor(1)), ('Ġa', tensor(1)), ('Ġnet', tensor(1)), ('book', tensor(1)), ('Ġpc', tensor(1)), ('ĠDO', tensor(1)), ('ĠNOT', tensor(1)), ('ĠBU', tensor(1)), ('Y', tensor(1)), ('ĠFROM', tensor(1)), ('ĠASUS', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('Its', tensor(1)), ('Ġvery', tensor(1)), ('Ġnice', tensor(1)), ('Ġand', tensor(1)), ('Ġonce', tensor(1)), ('Ġyou', tensor(1)), ('Ġlearn', tensor(1)), ('Ġthe', tensor(1)), ('Ġfeatures', tensor(1)), ('Ġyou', tensor(1)), ('Ġwill', tensor(1)), ('Ġbe', tensor(1)), ('Ġso', tensor(1)), ('Ġhappy', tensor(1)), ('Ġto', tensor(1)), ('Ġhave', tensor(1)), ('Ġsuch', tensor(1)), ('Ġa', tensor(1)), ('Ġsophisticated', tensor(1)), ('Ġcomputer', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(9), tensor(9), tensor(2), tensor(1.7235)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('But', tensor(1)), ('Ġthen', tensor(1)), ('Ġsomething', tensor(1)), ('Ġgoes', tensor(1)), ('Ġwrong', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('In', tensor(1)), ('Ġshort', tensor(1)), ('Ġyou', tensor(1)), ('Ġcould', tensor(1)), ('Ġsay', tensor(1)), ('Ġyour', tensor(1)), ('Ġmac', tensor(1)), ('Ġcould', tensor(1)), ('Ġbecome', tensor(1)), ('Ġyour', tensor(1)), ('Ġbest', tensor(1)), ('Ġfriend', tensor(1)), ('Ġno', tensor(1)), ('Ġintention', tensor(1)), ('Ġof', tensor(1)), ('Ġreplacing', tensor(1)), ('ĠRover', tensor(1)), ('Ġyour', tensor(1)), ('Ġdog', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('It', tensor(1)), ('Ġwas', tensor(1)), ('Ġtruly', tensor(1)), ('Ġa', tensor(1)), ('Ġgreat', tensor(1)), ('Ġcomputer', tensor(1)), ('Ġcosting', tensor(1)), ('Ġless', tensor(1)), ('Ġthan', tensor(1)), ('Ġone', tensor(1)), ('Ġthousand', tensor(1)), ('Ġbucks', tensor(1)), ('Ġbefore', tensor(1)), ('Ġtax', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(7), tensor(7), tensor(0), tensor(1.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġlove', tensor(1)), ('Ġthis', tensor(1)), ('Ġlittle', tensor(1)), ('Ġone', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('The', tensor(1)), ('Ġlove', tensor(1)), ('Ġpart', tensor(1)), ('Ġof', tensor(1)), ('Ġmy', tensor(1)), ('Ġrelationship', tensor(1)), ('Ġwith', tensor(1)), ('Ġthis', tensor(1)), ('Ġlaptop', tensor(1)), ('Ġdoes', tensor(1)), ('Ġn', tensor(1)), (\"'t\", tensor(1)), ('Ġtake', tensor(1)), ('Ġvery', tensor(1)), ('Ġlong', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('If', tensor(1)), ('Ġyou', tensor(1)), ('Ġfaintly', tensor(1)), ('Ġcome', tensor(1)), ('Ġclose', tensor(1)), ('Ġto', tensor(1)), ('Ġtouching', tensor(1)), ('Ġthis', tensor(1)), ('Ġthing', tensor(1)), ('Ġwhile', tensor(1)), ('Ġtyping', tensor(1)), ('Ġall', tensor(1)), ('Ġcraz', tensor(1)), ('iness', tensor(1)), ('Ġmay', tensor(1)), ('Ġbreak', tensor(1)), ('Ġloose', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('Ġactually', tensor(1)), ('Ġcontact', tensor(1)), ('ĠTos', tensor(1)), ('hiba', tensor(1)), ('Ġbefore', tensor(1)), ('ĠI', tensor(1)), ('Ġstarted', tensor(1)), ('Ġhaving', tensor(1)), ('Ġproblem', tensor(1)), ('Ġand', tensor(1)), ('Ġwas', tensor(1)), ('Ġgiven', tensor(1)), ('Ġrun', tensor(1)), ('Ġaround', tensor(1)), ('Ġafter', tensor(1)), ('ĠI', tensor(1)), ('Ġsupplied', tensor(1)), ('Ġserial', tensor(1)), ('Ġnumber', tensor(1)), ('Ġin', tensor(1)), ('Ġorder', tensor(1)), ('Ġto', tensor(1)), ('Ġdelay', tensor(1)), ('Ġme', tensor(1)), ('Ġsending', tensor(1)), ('Ġin', tensor(1)), ('Ġlaptop', tensor(1)), ('Ġuntil', tensor(1)), ('Ġafter', tensor(1)), ('Ġwar', tensor(1)), ('rent', tensor(1)), ('y', tensor(1)), ('Ġexpired', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(31), tensor(33), tensor(1), tensor(1.3820)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('The', tensor(1)), ('Ġgreat', tensor(1)), ('Ġ18', tensor(1)), ('Ġmonth', tensor(1)), ('Ġsame', tensor(1)), ('Ġas', tensor(1)), ('Ġcash', tensor(1)), ('Ġfinancing', tensor(1)), ('Ġand', tensor(1)), ('ĠAdvance', tensor(1)), ('ĠProtection', tensor(1)), ('ĠPlan', tensor(1)), ('Ġwhich', tensor(1)), ('Ġincludes', tensor(1)), ('Ġaccidents', tensor(1)), ('Ġlike', tensor(1)), ('Ġspills', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('I', tensor(1)), ('ĠHave', tensor(1)), ('Ġa', tensor(1)), ('Ġfriend', tensor(1)), ('Ġwho', tensor(1)), ('Ġhas', tensor(1)), ('Ġthe', tensor(1)), ('Ġother', tensor(1)), ('Ġmodel', tensor(1)), ('Ġand', tensor(1)), ('Ġwe', tensor(1)), ('Ġput', tensor(1)), ('Ġthem', tensor(1)), ('Ġside', tensor(1)), ('Ġby', tensor(1)), ('Ġside', tensor(1)), ('Ġwith', tensor(1)), ('Ġthe', tensor(1)), ('Ġsame', tensor(1)), ('Ġd', tensor(1)), ('vd', tensor(1)), ('Ġin', tensor(1)), ('Ġbattle', tensor(1)), ('Ġof', tensor(1)), ('Ġthe', tensor(1)), ('ĠSmithsonian', tensor(1)), ('ĠAfter', tensor(1)), ('Ġon', tensor(1)), ('ĠHour', tensor(1)), ('Ġmine', tensor(1)), ('Ġwas', tensor(1)), ('Ġat', tensor(1)), ('Ġ53', tensor(1)), ('Ġlife', tensor(1)), ('Ġleft', tensor(1)), ('Ġand', tensor(1)), ('Ġhis', tensor(1)), ('Ġwas', tensor(1)), ('Ġat', tensor(1)), ('Ġ69', tensor(1)), ('Ġlife', tensor(1)), ('Ġleft', tensor(1)), ('</s>', tensor(1))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('Small', tensor(1)), ('Ġenough', tensor(1)), ('Ġto', tensor(1)), ('Ġuse', tensor(1)), ('Ġon', tensor(1)), ('Ġa', tensor(1)), ('Ġlong', tensor(1)), ('Ġflight', tensor(1)), ('ĠLight', tensor(1)), ('Ġenough', tensor(1)), ('Ġto', tensor(1)), ('Ġcarry', tensor(1)), ('Ġthrough', tensor(1)), ('Ġairports', tensor(1)), ('Ġand', tensor(1)), ('Ġpowerful', tensor(1)), ('Ġenough', tensor(1)), ('Ġto', tensor(1)), ('Ġreplace', tensor(1)), ('Ġmy', tensor(1)), ('Ġdesktop', tensor(1)), ('Ġwhile', tensor(1)), ('Ġon', tensor(1)), ('Ġlong', tensor(1)), ('Ġbusiness', tensor(1)), ('Ġtrips', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(12), tensor(12), tensor(0), tensor(1.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('And', tensor(1)), ('ĠI', tensor(1)), ('Ġm', tensor(1)), ('Ġstill', tensor(1)), ('Ġpaying', tensor(1)), ('Ġthe', tensor(1)), ('Ġbloody', tensor(1)), ('Ġfinancing', tensor(1)), ('Ġfor', tensor(1)), ('Ġa', tensor(1)), ('Ġproduct', tensor(1)), ('Ġwhich', tensor(1)), ('Ġdid', tensor(1)), ('Ġn', tensor(1)), (\"'t\", tensor(1)), ('Ġlast', tensor(1)), ('Ġme', tensor(1)), ('Ġat', tensor(1)), ('Ġleast', tensor(1)), ('Ġthree', tensor(1)), ('Ġyears', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n",
            "[('<s>', tensor(1)), ('The', tensor(1)), ('Ġdisplay', tensor(1)), ('Ġis', tensor(1)), ('Ġbeyond', tensor(1)), ('Ġhorrible', tensor(1)), ('</s>', tensor(1)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0)), ('<pad>', tensor(0))]\n",
            "[(tensor(2), tensor(2), tensor(1), tensor(1.3820)), (tensor(0), tensor(0), tensor(4), tensor(0.)), (tensor(0), tensor(0), tensor(4), tensor(0.))]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSxu8r1KIydy"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjchaEolI1_C"
      },
      "source": [
        "import transformers.models.roberta.modeling_roberta\n",
        "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel, RobertaModel\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "\n",
        "def get_aspect_terms_word_pieces(start_indexes, end_indexes, contextualized_embs, embs_mask):\n",
        "    sentences_length = torch.sum(embs_mask, dim=-1)\n",
        "    terms_offset = torch.cumsum(sentences_length, dim=0)\n",
        "    terms_offset -= sentences_length\n",
        "    start_indexes_offset = (start_indexes + terms_offset.unsqueeze(1)).view(-1)\n",
        "    end_indexes_offset = (end_indexes + terms_offset.unsqueeze(1)).view(-1)\n",
        "\n",
        "    number_of_word_pieces_per_aspect_term = end_indexes_offset - start_indexes_offset + 1\n",
        "    max_aspect_term_len = torch.max(number_of_word_pieces_per_aspect_term)\n",
        "    embs_mask = embs_mask.view(-1)\n",
        "    batch_size, sequence_length, hidden_dim = contextualized_embs.shape\n",
        "    contextualized_embs = contextualized_embs.view(batch_size * sequence_length, hidden_dim)\n",
        "    contextualized_embs = contextualized_embs[embs_mask.nonzero().squeeze(), :]\n",
        "    text_length = contextualized_embs.shape[0]\n",
        "\n",
        "    aspect_terms_word_pieces_indexes = torch.arange(max_aspect_term_len).unsqueeze(0).to(start_indexes_offset.device) + start_indexes_offset.unsqueeze(1)\n",
        "    aspect_terms_word_pieces_indexes = torch.min(aspect_terms_word_pieces_indexes, (text_length - 1) * torch.ones_like(aspect_terms_word_pieces_indexes))\n",
        "    aspect_terms_word_pieces = contextualized_embs[aspect_terms_word_pieces_indexes, :]\n",
        "    word_pieces_indexes_range = torch.arange(max_aspect_term_len).to(number_of_word_pieces_per_aspect_term.device)\n",
        "    aspect_terms_word_pieces_mask = word_pieces_indexes_range < number_of_word_pieces_per_aspect_term.unsqueeze(-1)\n",
        "    return aspect_terms_word_pieces, aspect_terms_word_pieces_mask.long()\n",
        "\n",
        "def get_aspect_terms_representation(aspect_terms_word_pieces, attention_scores, aspect_terms_word_pieces_mask):\n",
        "    aspect_terms_word_pieces_mask = (1.0 - aspect_terms_word_pieces_mask) * -100000.0\n",
        "    attention_scores = attention_scores + aspect_terms_word_pieces_mask # To avoid to consider padding in the self-attention combination\n",
        "    probs = (nn.Softmax(dim=-1)(attention_scores)).unsqueeze(-1)\n",
        "    return torch.sum(probs * aspect_terms_word_pieces, dim=1)\n",
        "\n",
        "class RobertaForAspectTermClassification(RobertaPreTrainedModel):\n",
        "\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
        "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        if VARIANT_TO_TEST not in VARIANTS:\n",
        "          raise RuntimeError('The inserted VARIANT is not valid')\n",
        "        \n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.linear = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.a = nn.Linear(config.hidden_size, 1) # It is the a vector named in the report\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=True,\n",
        "        return_dict=None,\n",
        "        start_indexes=None,\n",
        "        end_indexes=None,\n",
        "        label_masks=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
        "            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n",
        "            1]``.\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        output_hidden_states = VARIANT_TO_TEST in {'Average Last Four Hidden', 'Sum Last Four Hidden'}\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        if VARIANT_TO_TEST in {'INS', 'ISNS', 'ENS', 'ATPC with sqrt', 'ATPC'}:\n",
        "          sequence_output = outputs[0]\n",
        "        else:\n",
        "          hidden_states = outputs.hidden_states[1:] if return_dict else outputs[2][1:]\n",
        "          stacked_last_four_layers = torch.stack(hidden_states[-4:], dim=0)\n",
        "          sequence_output = stacked_last_four_layers.mean(dim=0) if VARIANT_TO_TEST == 'Average Last Four Hidden' else stacked_last_four_layers.sum(dim=0)\n",
        "\n",
        "        aspect_terms_word_pieces, aspect_terms_word_pieces_mask = get_aspect_terms_word_pieces(start_indexes, end_indexes, sequence_output, attention_mask)\n",
        "\n",
        "        attention_scores = (self.a(aspect_terms_word_pieces)).squeeze(-1)\n",
        "        aspect_terms_representation = get_aspect_terms_representation(aspect_terms_word_pieces, attention_scores, aspect_terms_word_pieces_mask)\n",
        "\n",
        "        aspect_terms_representation = self.linear(aspect_terms_representation)\n",
        "        aspect_terms_representation = self.tanh(aspect_terms_representation)\n",
        "        aspect_terms_representation = self.dropout(aspect_terms_representation)\n",
        "        logits = self.classifier(aspect_terms_representation)\n",
        "        loss_function = CrossEntropyLoss(reduction='none') # If I use ignore_index, it still considers it in the normalization\n",
        "        label_masks = label_masks.view(-1)\n",
        "        loss = loss_function(logits, labels.view(-1))\n",
        "        loss = torch.sum(loss * label_masks.to(dtype=loss.dtype)) / torch.sum(label_masks.to(dtype=loss.dtype))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return TokenClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biedTKebdj3k"
      },
      "source": [
        "class AspectTermClassificationModel(nn.Module):\n",
        "    # we provide the hyperparameters as input\n",
        "    def __init__(self, hparams):\n",
        "        super(AspectTermClassificationModel, self).__init__()\n",
        "        pprint(hparams)\n",
        "\n",
        "        self.roberta = RobertaForAspectTermClassification.from_pretrained(hparams.bert_model, num_labels=hparams.num_labels)\n",
        "\n",
        "    \n",
        "    def forward(self, x, start_indexes, end_indexes, label_masks):\n",
        "      b_input_ids, b_input_mask, b_labels = x\n",
        "      outputs = self.roberta(b_input_ids, token_type_ids=None,\n",
        "                          attention_mask=b_input_mask, labels=b_labels,\n",
        "                          start_indexes=start_indexes, end_indexes=end_indexes,\n",
        "                          label_masks=label_masks)\n",
        "      loss, logits = outputs[0], outputs[1]\n",
        "      return loss, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbSdWte2erdg"
      },
      "source": [
        "def get_sentiment_results(sentiment_types, scores):\n",
        "\n",
        "  # Compute per sentiment Precision / Recall / F1\n",
        "    for sent_type in scores.keys():\n",
        "        if scores[sent_type][\"tp\"]:\n",
        "            scores[sent_type][\"p\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fp\"] + scores[sent_type][\"tp\"])\n",
        "            scores[sent_type][\"r\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fn\"] + scores[sent_type][\"tp\"])\n",
        "        else:\n",
        "            scores[sent_type][\"p\"], scores[sent_type][\"r\"] = 0, 0\n",
        "\n",
        "        if not scores[sent_type][\"p\"] + scores[sent_type][\"r\"] == 0:\n",
        "            scores[sent_type][\"f1\"] = 2 * scores[sent_type][\"p\"] * scores[sent_type][\"r\"] / (\n",
        "                    scores[sent_type][\"p\"] + scores[sent_type][\"r\"])\n",
        "        else:\n",
        "            scores[sent_type][\"f1\"] = 0\n",
        "\n",
        "    # Compute micro F1 Scores\n",
        "    tp = sum([scores[sent_type][\"tp\"] for sent_type in sentiment_types])\n",
        "    fp = sum([scores[sent_type][\"fp\"] for sent_type in sentiment_types])\n",
        "    fn = sum([scores[sent_type][\"fn\"] for sent_type in sentiment_types])\n",
        "\n",
        "    if tp:\n",
        "        precision = 100 * tp / (tp + fp)\n",
        "        recall = 100 * tp / (tp + fn)\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    else:\n",
        "        precision, recall, f1 = 0, 0, 0\n",
        "\n",
        "    scores[\"ALL\"][\"p\"] = precision\n",
        "    scores[\"ALL\"][\"r\"] = recall\n",
        "    scores[\"ALL\"][\"f1\"] = f1\n",
        "    scores[\"ALL\"][\"tp\"] = tp\n",
        "    scores[\"ALL\"][\"fp\"] = fp\n",
        "    scores[\"ALL\"][\"fn\"] = fn\n",
        "\n",
        "    # Compute Macro F1 Scores\n",
        "    scores[\"ALL\"][\"Macro_f1\"] = sum([scores[ent_type][\"f1\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_p\"] = sum([scores[ent_type][\"p\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_r\"] = sum([scores[ent_type][\"r\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "        \n",
        "    return scores, precision, recall, f1\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_sentiment(samples, predictions_b):\n",
        "    scores = {}\n",
        "    sentiment_types = [\"positive\", \"negative\", \"neutral\", \"conflict\"]\n",
        "    scores = {sent: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for sent in sentiment_types + [\"ALL\"]}\n",
        "    for label, pred in zip(samples, predictions_b):\n",
        "      for sentiment in sentiment_types:\n",
        "        pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"targets\"] if term_pred[1] == sentiment}\n",
        "        gt_sent = {(term_pred[0], term_pred[1]) for term_pred in label[\"targets\"] if term_pred[1] == sentiment}\n",
        "\n",
        "        scores[sentiment][\"tp\"] += len(pred_sent & gt_sent)\n",
        "        scores[sentiment][\"fp\"] += len(pred_sent - gt_sent)\n",
        "        scores[sentiment][\"fn\"] += len(gt_sent - pred_sent)\n",
        "\n",
        "    return get_sentiment_results(sentiment_types, scores)\n",
        "\n",
        "    \n",
        "        \n",
        "def get_metrics_results(true_outputs: List[Dict[str, List[Tuple[str, str]]]], predictions: List[List[str]]) -> None:\n",
        "  aspect_terms_polarities_predictions = list()\n",
        "  \n",
        "  for (true_output, pred_output) in zip(true_outputs, predictions):\n",
        "    prediction = {'targets': []}\n",
        "    \n",
        "    for (aspect_term, true_polarity), pred_polarity in zip(true_output['targets'], pred_output):\n",
        "      prediction['targets'].append((aspect_term, pred_polarity))\n",
        "\n",
        "    aspect_terms_polarities_predictions.append(prediction)\n",
        "\n",
        "  return evaluate_sentiment(true_outputs, aspect_terms_polarities_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utWq09kiiNnx"
      },
      "source": [
        "from torchmetrics import F1\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import AdamW\n",
        "\n",
        "\n",
        "class PolarityModule(pl.LightningModule):\n",
        "    def __init__(self, hparams, *args, **kwargs):\n",
        "        super(PolarityModule, self).__init__(*args, **kwargs)\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model: the model we want to train.\n",
        "            loss_function: the loss_function to minimize.\n",
        "            optimizer: the optimizer used to minimize the loss_function.\n",
        "        \"\"\"\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.F1 = F1(num_classes=self.hparams.num_labels, average='macro', ignore_index=ABSA_B_Dataset.padding_polarity_index)\n",
        "        self.model = AspectTermClassificationModel(self.hparams)\n",
        "        self.sent_scores = {sent: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for sent in ['positive', 'negative', 'neutral', 'conflict']}\n",
        "    # This performs a forward pass of the model, as well as returning the predicted index.\n",
        "    def forward(self, x, start_indexes, end_indexes, label_masks):\n",
        "        outputs = self.model(x, start_indexes, end_indexes, label_masks)\n",
        "        return outputs\n",
        "\n",
        "    # This runs the model in training mode mode, ie. activates dropout and gradient computation. It defines a single training step.\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        labels = batch['outputs']\n",
        "        inputs = (batch['inputs'], batch['attention_masks'], labels)\n",
        "\n",
        "        loss, logits = self.forward(inputs, batch['start_indexes'], batch['end_indexes'], batch['label_masks'])\n",
        "        \n",
        "        predictions = torch.argmax(logits, -1)\n",
        "        labels = labels.view(-1)\n",
        "        assert predictions.shape == labels.shape\n",
        "        predictions = torch.tensor([int(p) for p, l in zip(predictions, labels) if int(l) != ABSA_B_Dataset.padding_polarity_index]).to(self.hparams.device)\n",
        "        \n",
        "        labels = torch.tensor([int(l) for l in labels if int(l) != ABSA_B_Dataset.padding_polarity_index]).to(self.hparams.device)\n",
        "\n",
        "        assert predictions.shape == labels.shape\n",
        "        F1 = self.F1(predictions, labels)\n",
        "        # Log it:\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_f1', F1, prog_bar=True)\n",
        "        # Very important for PL to return the loss that will be used to update the weights:\n",
        "        return loss\n",
        "\n",
        "\n",
        "    # This runs the model in eval mode, ie. sets dropout to 0 and deactivates grad. Needed when we are in inference mode.\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        labels = batch['outputs']\n",
        "        inputs = (batch['inputs'], batch['attention_masks'], labels)\n",
        "        \n",
        "        sample_loss, logits = self.forward(inputs, batch['start_indexes'], batch['end_indexes'], batch['label_masks'])\n",
        "\n",
        "        predictions = torch.argmax(logits, -1)\n",
        "        labels = labels.view(-1)\n",
        "        assert predictions.shape == labels.shape\n",
        "        predictions = torch.tensor([int(p) for p, l in zip(predictions, labels) if int(l) != ABSA_B_Dataset.padding_polarity_index]).to(self.hparams.device)\n",
        "        \n",
        "        labels = torch.tensor([int(l) for l in labels if int(l) != ABSA_B_Dataset.padding_polarity_index]).to(self.hparams.device)\n",
        "\n",
        "        assert predictions.shape == labels.shape\n",
        "        sample_F1 = self.F1(predictions, labels)\n",
        "\n",
        "        self.log('valid_loss', sample_loss, prog_bar=True)\n",
        "        self.log('valid_f1', sample_F1, prog_bar=True)\n",
        "\n",
        "    # This runs the model in eval mode, ie. sets dropout to 0 and deactivates grad. Needed when we are in inference mode.\n",
        "    def test_step(self, batch, batch_nb):\n",
        "        labels = batch['outputs']\n",
        "        inputs_indexes = batch['inputs']\n",
        "\n",
        "        inputs = (inputs_indexes, batch['attention_masks'], labels)\n",
        "\n",
        "        sample_loss, logits = self.forward(inputs, batch['start_indexes'], batch['end_indexes'], batch['label_masks'])\n",
        "\n",
        "        batch_size = labels.size()[0]\n",
        "        max_number_of_aspect_terms = labels.size()[1]\n",
        "        sequence_length = logits.size()[1]\n",
        "        logits = logits.view([batch_size, max_number_of_aspect_terms, sequence_length])\n",
        "\n",
        "        predictions = torch.argmax(logits, -1)\n",
        "\n",
        "        predictions = [[int(p_i) for p_i, l_i in zip(p, l) if int(l_i) != ABSA_B_Dataset.padding_polarity_index]\n",
        "                                 for p, l in zip(predictions, labels)]\n",
        "\n",
        "        labels = torch.tensor([int(l_i) for l in labels\n",
        "                                        for l_i in l if int(l_i) != ABSA_B_Dataset.padding_polarity_index]).to(self.hparams.device)\n",
        "        decoded_labels = ABSA_B_Dataset.decode_output(predictions)\n",
        "\n",
        "        scores, precision, recall, f1 = get_metrics_results(batch['true_outputs'], decoded_labels)\n",
        "        for sentiment in self.sent_scores:\n",
        "          self.sent_scores[sentiment]['tp'] += scores[sentiment]['tp']\n",
        "          self.sent_scores[sentiment]['fp'] += scores[sentiment]['fp']\n",
        "          self.sent_scores[sentiment]['fn'] += scores[sentiment]['fn']\n",
        "\n",
        "\n",
        "        predictions = torch.tensor([prediction for sample_predictions in predictions for prediction in sample_predictions]).to(self.hparams.device)\n",
        "        assert predictions.shape == labels.shape\n",
        "        sample_F1 = self.F1(predictions, labels)\n",
        "        \n",
        "        \n",
        "        self.log('test_loss', sample_loss, prog_bar=True)\n",
        "        self.log('test_f1_on_NE_labels', sample_F1, prog_bar=True)\n",
        "        self.log('test_macro_precision', scores[\"ALL\"][\"Macro_p\"], prog_bar=True)\n",
        "        self.log('test_macro_recall', scores[\"ALL\"][\"Macro_r\"], prog_bar=True)\n",
        "        self.log('test_macro_f1', scores[\"ALL\"][\"Macro_f1\"], prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      if self.hparams.full_finetuning:\n",
        "          parameters_optimizer = list(self.model.roberta.named_parameters())\n",
        "          without_decay = ['bias', 'gamma', 'beta']\n",
        "          optimizer_grouped_parameters = [\n",
        "              {'params': [p for n, p in parameters_optimizer if not any(wd in n for wd in without_decay)],\n",
        "              'weight_decay_rate': 0.01},\n",
        "              {'params': [p for n, p in parameters_optimizer if any(wd in n for wd in without_decay)],\n",
        "              'weight_decay_rate': 0.0}\n",
        "          ]\n",
        "      else:\n",
        "          parameters_optimizer = list(self.model.roberta.classifier.named_parameters())\n",
        "          optimizer_grouped_parameters = [{\"params\": [p for n, p in parameters_optimizer]}]\n",
        "\n",
        "      optimizer = AdamW(\n",
        "          optimizer_grouped_parameters,\n",
        "          lr=3e-5,\n",
        "          eps=1e-8\n",
        "      )\n",
        "\n",
        "      total_train_steps = self.hparams.n_batches * self.hparams.n_epochs\n",
        "\n",
        "      scheduler = get_linear_schedule_with_warmup(\n",
        "          optimizer,\n",
        "          num_warmup_steps=0,\n",
        "          num_training_steps=total_train_steps\n",
        "      )\n",
        "\n",
        "      return [optimizer], [scheduler]\n",
        "    \n",
        "    def print_test_results(self):\n",
        "      # Compute per sentiment Precision / Recall / F1\n",
        "      scores = self.sent_scores\n",
        "      sentiment_types = [\"positive\", \"negative\", \"neutral\", \"conflict\"]\n",
        "      scores[\"ALL\"] = {\"tp\": 0, \"fp\": 0, \"fn\": 0}\n",
        "      scores, precision, recall, f1 = get_sentiment_results(sentiment_types, scores)\n",
        "\n",
        "      print(\"Evaluation\\n\")\n",
        "\n",
        "      print(\n",
        "          \"\\tALL\\t TP: {};\\tFP: {};\\tFN: {}\".format(\n",
        "              scores[\"ALL\"][\"tp\"],\n",
        "              scores[\"ALL\"][\"fp\"],\n",
        "              scores[\"ALL\"][\"fn\"]))\n",
        "      print(\n",
        "          \"\\t\\t(m avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (micro)\".format(\n",
        "              precision,\n",
        "              recall,\n",
        "              f1))\n",
        "      print(\n",
        "          \"\\t\\t(M avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (Macro)\\n\".format(\n",
        "              scores[\"ALL\"][\"Macro_p\"],\n",
        "              scores[\"ALL\"][\"Macro_r\"],\n",
        "              scores[\"ALL\"][\"Macro_f1\"]))\n",
        "\n",
        "      for sent_type in sentiment_types:\n",
        "          print(\"\\t{}: \\tTP: {};\\tFP: {};\\tFN: {};\\tprecision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f};\\t{}\".format(\n",
        "              sent_type,\n",
        "              scores[sent_type][\"tp\"],\n",
        "              scores[sent_type][\"fp\"],\n",
        "              scores[sent_type][\"fn\"],\n",
        "              scores[sent_type][\"p\"],\n",
        "              scores[sent_type][\"r\"],\n",
        "              scores[sent_type][\"f1\"],\n",
        "              scores[sent_type][\"tp\"] +\n",
        "              scores[sent_type][\"fn\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvtelIeLwud1"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562,
          "referenced_widgets": [
            "8b871ee83b57453bac912a24359b2f2e",
            "8b85555d7ead41e9bc188495e8b2b1db",
            "18ea6b7bb694413ba3d11922b9cbdb5d",
            "504da1b4c5ca48d890f2384c3ff3632b",
            "26f91f427dab4ab091acf8c7dd970316",
            "e6ab4f6e8ef14ce1a9d5b2a7eb8253ab",
            "16affebb6f624f8083500095d72b79b4",
            "2ace84513c084a10abef7facbc342ce5",
            "bee863634b464596b52f363f9542d93d",
            "16d0c6cc999d4658bf507406538cdb9c",
            "4d0a9910b4d94f42b46186b769384e20",
            "10f8e1ae03354b3aab3a4209527caa1a",
            "6fc64f90ba9a4cb5a453cabc7dafb624",
            "4b6a8157207e4a04b615eeba1792f4dd",
            "6ad0965093904cd1bf891f555dc3d1a1",
            "b9fa191ebb244165b4cc3e8c8bc3fa20",
            "553feaddeb7e48d9bd7f82658cf07bd2",
            "57751a227cdd446d900ab79dd73b41f7",
            "e00a8c622f2543b9ba46a2d8aec1a9f8",
            "e188d3f334f9466794614c0cdefd3196",
            "9754526d0e204fc7993604f101b341e4",
            "7d0b26ccb81143e98dab7d4ffcc6581b",
            "2dbe4bbb81094802915155d1b423f723",
            "c753fc3139e246bcbcf947f29e2d1ac7",
            "820382df274641efb9fd3f109d925f9a",
            "6dade08bf1674298af9191536a16079e",
            "0fb8751415f94180afdc5369b21fc54d",
            "921afc97ed944cafac25c5a3477ef19e",
            "9cc2a32c6dc749b1a979a777f51cc2b8",
            "3934b03772c544059cb4acbfe837e97e",
            "17536f77c4d84d31bd63355f0cd46c84",
            "3db5788dfecc44b9adaeffc0c76797e7"
          ]
        },
        "id": "sHlYLY1OwvHF",
        "outputId": "1dd8472b-35f5-45bd-f107-11305bf79165"
      },
      "source": [
        "MAX_GRAD_NORM = 1.0\n",
        "\n",
        "check_point_callback = pl.callbacks.ModelCheckpoint(\n",
        "    monitor='valid_loss',  # the value that we want to use for model selection.\n",
        "    verbose=True,  # whether to log or not information in the console.\n",
        "    save_top_k=1,  # the number of checkpoints we want to store.\n",
        "    mode='min',  # wheter we want to maximize (max) or minimize the \"monitor\" value.\n",
        "    dirpath='experiments/Aspect_Term_Classifier',  # output directory path\n",
        "    filename='{epoch}-{valid_loss:.4f}'  # the prefix on the checkpoint values. Metrics store by the trainer can be used to dynamically change the name.\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "hparams = {'num_labels': len(ABSA_B_Dataset.polarities), # number of different NE labels in our case\n",
        "           'bert_model': BERT_MODEL,\n",
        "           'full_finetuning': True,\n",
        "           'n_epochs': 3,\n",
        "           'device': 'cuda' if torch.cuda.is_available() else 'cpu'}\n",
        "\n",
        "# sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
        "pl.seed_everything(SEED, workers=True)\n",
        "\n",
        "data_module = DataModuleABSA_B(train_dataframe['targets'], train_dataframe['text'], valid_dataframe['targets'], valid_dataframe['text'])\n",
        "data_module.setup()\n",
        "n_batches = len(data_module.train_dataloader())\n",
        "hparams['n_batches'] = n_batches\n",
        "data_module = None\n",
        "data_module = DataModuleABSA_B(train_dataframe['targets'], train_dataframe['text'], valid_dataframe['targets'], valid_dataframe['text'])\n",
        "train_dataframe = None\n",
        "valid_dataframe = None\n",
        "\n",
        "trainer = pl.Trainer(gpus=1 if torch.cuda.is_available() else 0,\n",
        "                     val_check_interval=1.0,\n",
        "                     deterministic=True,\n",
        "                     max_epochs=hparams['n_epochs'] - 1,\n",
        "                     gradient_clip_val=MAX_GRAD_NORM,\n",
        "                     callbacks=[check_point_callback] # the callback we want our trainer to use.\n",
        ")\n",
        "\n",
        "model = PolarityModule(hparams)\n",
        "trainer.fit(model, datamodule=data_module)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1234\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bert_model': 'roberta-large',\n",
            " 'device': 'cuda',\n",
            " 'full_finetuning': True,\n",
            " 'n_batches': 157,\n",
            " 'n_epochs': 3,\n",
            " 'num_labels': 5}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForAspectTermClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForAspectTermClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForAspectTermClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForAspectTermClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['linear.bias', 'classifier.weight', 'a.weight', 'classifier.bias', 'linear.weight', 'a.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                          | Params\n",
            "--------------------------------------------------------\n",
            "0 | F1    | F1                            | 0     \n",
            "1 | model | AspectTermClassificationModel | 355 M \n",
            "--------------------------------------------------------\n",
            "355 M     Trainable params\n",
            "0         Non-trainable params\n",
            "355 M     Total params\n",
            "1,421.464 Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b871ee83b57453bac912a24359b2f2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1234\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bee863634b464596b52f363f9542d93d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "553feaddeb7e48d9bd7f82658cf07bd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, global step 156: valid_loss reached 0.78722 (best 0.78722), saving model to \"/content/experiments/Aspect_Term_Classifier/epoch=0-valid_loss=0.7872.ckpt\" as top 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "820382df274641efb9fd3f109d925f9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, global step 313: valid_loss reached 0.68218 (best 0.68218), saving model to \"/content/experiments/Aspect_Term_Classifier/epoch=1-valid_loss=0.6822.ckpt\" as top 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41ZnwxakBkrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "4b8ad08b72874289ad9e1f1e50790306",
            "f7aba2a194884b6fbbaf479aea1657c1",
            "2fed131fc0a14d95a9bc3d5af8b547b3",
            "291f127e83dc4d5b973b90b8c3fbcbf5",
            "c773b070e04347de9245253cb6f6e36d",
            "505c86961eb74475979dcafce8366ad7",
            "5c8908810b8f4d2e80981a33f9e29b74",
            "714c011cf70242d8b2806324902d1704"
          ]
        },
        "outputId": "c75acf78-57ab-4f21-b10c-8edc7deeefa2"
      },
      "source": [
        "test_set_results = trainer.test(model, test_dataloaders=data_module.test_dataloader())\n",
        "print(\"test set results: {}\".format(test_set_results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b8ad08b72874289ad9e1f1e50790306",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_f1_on_NE_labels': 0.6767185926437378,\n",
            " 'test_loss': 0.682178258895874,\n",
            " 'test_macro_f1': 67.69412231445312,\n",
            " 'test_macro_precision': 67.98619079589844,\n",
            " 'test_macro_recall': 68.80020904541016}\n",
            "--------------------------------------------------------------------------------\n",
            "test set results: [{'test_loss': 0.682178258895874, 'test_f1_on_NE_labels': 0.6767185926437378, 'test_macro_precision': 67.98619079589844, 'test_macro_recall': 68.80020904541016, 'test_macro_f1': 67.69412231445312}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARr9qcIWdDOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa99e24e-e9d8-4214-d920-6e69f766976f"
      },
      "source": [
        "model.print_test_results()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "\n",
            "\tALL\t TP: 863;\tFP: 222;\tFN: 223\n",
            "\t\t(m avg): precision: 79.54;\trecall: 79.47;\tf1: 79.50 (micro)\n",
            "\t\t(M avg): precision: 67.84;\trecall: 66.47;\tf1: 66.95 (Macro)\n",
            "\n",
            "\tpositive: \tTP: 489;\tFP: 84;\tFN: 54;\tprecision: 85.34;\trecall: 90.06;\tf1: 87.63;\t543\n",
            "\tnegative: \tTP: 248;\tFP: 66;\tFN: 54;\tprecision: 78.98;\trecall: 82.12;\tf1: 80.52;\t302\n",
            "\tneutral: \tTP: 116;\tFP: 57;\tFN: 100;\tprecision: 67.05;\trecall: 53.70;\tf1: 59.64;\t216\n",
            "\tconflict: \tTP: 10;\tFP: 15;\tFN: 15;\tprecision: 40.00;\trecall: 40.00;\tf1: 40.00;\t25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SR0O8BGzjop"
      },
      "source": [
        "! rm -r experiments"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}